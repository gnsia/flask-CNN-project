{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy.linalg as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 기초\n",
    "- inverse를 통한 mnist 학습\n",
    "- 신경망을 통한 mnist 학습\n",
    "- CNN통한 minit 학습\n",
    "- fashion mnist, face db 테스트\n",
    "- web 연동(한글, 스케치인식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38 254\n",
      "  109   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  87 252\n",
      "   82   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 135 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 244 150\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  84 254  63\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 202 223  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  32 254 216   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  95 254 195   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 140 254  77   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  57 237 205   8   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 124 255 165   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 171 254  81   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  24 232 215   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 120 254 159   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 151 254 142   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 228 254  66   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  61 251 254  66   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 141 254 205   3   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  10 215 254 121   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5 198 176  10   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "(60000,)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "plt.imshow(X_train[2], cmap='gray')\n",
    "print(X_test.shape)\n",
    "plt.imshow(X_test[2], cmap='gray')\n",
    "print(X_test[2])\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 784))\n",
    "X_test = X_test.reshape((X_test.shape[0], 784))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_e = to_categorical(y_train)\n",
    "y_test_e = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 역행렬을 이용한 학습\n",
    "\n",
    "- y = W * [x 1]     y=wx    y=wx+b\n",
    "- A 60000x785(=784+1)\n",
    "- W = inv(A)*Y     , where Y = 60000x10,   W = 785x10\n",
    "- predict  [x 1] * W  , where x = 1x784    W = 785x10 ,  predict=1x10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n"
     ]
    }
   ],
   "source": [
    "A = np.hstack((X_train, np.ones((60000,1)) ))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 10)\n",
      "[[ 7.44778176e-17  3.08116485e-17  6.24517735e-17 ... -1.88247215e-17\n",
      "  -9.68761667e-17  2.74183832e-17]\n",
      " [ 2.72617137e-15  6.00860904e-15  5.60436230e-15 ... -3.27464737e-15\n",
      "  -7.94429899e-15  1.43796527e-15]\n",
      " [ 3.84484283e-16  2.05591053e-15  4.34029518e-16 ... -5.97620728e-16\n",
      "  -7.11142655e-16  5.59708728e-16]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.57799659e-01  2.41326501e-01  4.98284745e-02 ...  1.41540555e-01\n",
      "  -1.23002061e-01  4.55121243e-02]]\n",
      "Wall time: 4.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W = np.matmul(lin.pinv(A), y_train_e)\n",
    "print(W.shape)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785,)\n"
     ]
    }
   ],
   "source": [
    "print(W[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.8603\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.hstack((X_test, np.ones((10000,1)) ))\n",
    "p = np.matmul(T, W)\n",
    "print(p.shape)\n",
    "p  = np.argmax(p, axis=1)\n",
    "print(p.shape)\n",
    "print(p)\n",
    "plt.imshow(X_test[2,:].reshape(28,28), cmap='gray')\n",
    "\n",
    "print(np.mean(p == y_test) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],    \n",
    "              [7,8,9],\n",
    "              [4,10,6]])\n",
    "np.argmax(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#0.1   0.9    0.5       \n",
    "#0.1/(0.1+0.9+1.2)\n",
    "#exp(0.1)/(  exp(0.1)+  exp(0.9)+  exp(1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 10,\n",
    "                verbose = 1,\n",
    "                 batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.116631657415203\n",
      "Test accuracy: 0.8673999905586243\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.8674\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test)\n",
    "print(p.shape)\n",
    "p  = np.argmax(p, axis=1)\n",
    "print(p.shape)\n",
    "print(p)\n",
    "print(np.mean(p == y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7850\n"
     ]
    }
   ],
   "source": [
    "# 784 차원 + 1   : 분류가당 785개* 10 분류기 = 7850 \n",
    "print(784 *  10 + 10)    ,    input size * 뉴런수 + 뉴런수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# layer1 = 784* 5 + 5 \n",
    "print(784* 5 + 5)\n",
    "# layer2 = 5*  10 + 10\n",
    "print(5*  10 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 100,\n",
    "                verbose = 1,\n",
    "                 batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9666000008583069\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.0676 - accuracy: 0.8992\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.6012 - accuracy: 0.9445\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3014 - accuracy: 0.9569\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2034 - accuracy: 0.9642\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1696 - accuracy: 0.9675\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1669 - accuracy: 0.9688\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1531 - accuracy: 0.9690\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1355 - accuracy: 0.9711\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1327 - accuracy: 0.9710\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.1366 - accuracy: 0.9725\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1448 - accuracy: 0.9709\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1308 - accuracy: 0.9724\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1274 - accuracy: 0.9747\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1202 - accuracy: 0.9762\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1060 - accuracy: 0.9780\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1103 - accuracy: 0.9775\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1194 - accuracy: 0.9772\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1135 - accuracy: 0.9785\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0975 - accuracy: 0.9811\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0987 - accuracy: 0.9814\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1033 - accuracy: 0.9813\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1086 - accuracy: 0.9822\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0893 - accuracy: 0.9833\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0822 - accuracy: 0.9837\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0992 - accuracy: 0.9827\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0985 - accuracy: 0.9836\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0853 - accuracy: 0.9846\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0791 - accuracy: 0.9863\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0750 - accuracy: 0.9872\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0901 - accuracy: 0.9859\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0835 - accuracy: 0.9868\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0859 - accuracy: 0.9868\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0803 - accuracy: 0.9870\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0873 - accuracy: 0.9868\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0832 - accuracy: 0.9883\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0657 - accuracy: 0.9894\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0704 - accuracy: 0.9885\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0840 - accuracy: 0.9882\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0752 - accuracy: 0.9885\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0754 - accuracy: 0.9895\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0691 - accuracy: 0.9901\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0624 - accuracy: 0.9904\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0682 - accuracy: 0.9899\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0750 - accuracy: 0.9900\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0800 - accuracy: 0.9895\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0619 - accuracy: 0.9911\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0623 - accuracy: 0.9908\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0780 - accuracy: 0.9901\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0664 - accuracy: 0.9907\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0731 - accuracy: 0.9901\n",
      "Test accuracy: 0.96670001745224\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 50,\n",
    "                verbose = 1,\n",
    "                 batch_size=100)\n",
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2972 - accuracy: 0.9147\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0988 - accuracy: 0.9719\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0710 - accuracy: 0.9797\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0547 - accuracy: 0.9849\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0438 - accuracy: 0.9881\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0359 - accuracy: 0.9907\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0291 - accuracy: 0.9927\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0242 - accuracy: 0.9941\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0193 - accuracy: 0.9955\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0156 - accuracy: 0.9969\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0126 - accuracy: 0.9976\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0101 - accuracy: 0.9982\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0083 - accuracy: 0.9985\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0062 - accuracy: 0.9991\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0049 - accuracy: 0.9994\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0036 - accuracy: 0.9996\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0030 - accuracy: 0.9997\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0045 - accuracy: 0.9989\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 9.4507e-04 - accuracy: 0.9999\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 7.0919e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 4.6788e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 2.6907e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 2.0115e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.6866e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.4948e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.2129e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.4625e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 5.5612e-04 - accuracy: 0.9999\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 5.5152e-04 - accuracy: 0.9999\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.4788e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1.1148e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 7.2071e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 5.9688e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 5.1226e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 4.5049e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 3.6761e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 3.3666e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 2.6684e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 2.3908e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0090 - accuracy: 0.9976\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 2.0277e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.0645e-04 - accuracy: 1.0000\n",
      "Test accuracy: 0.9840999841690063\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 50,\n",
    "                verbose = 1,\n",
    "                 batch_size=100)\n",
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
